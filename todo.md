1. 성능 최적화
- mac m1에서 gemma3:1b llm응답시 6-12초 정도 걸림 
  - 최우선적으로는 퍼포먼스 튜닝이 필요
  - 리서치 결과 해당 모델이 최선인의 초이스인 것 같으나, 여전히 느린 응답 


- 실제 oci 무료 서버에 배포할 경우를 고려했을 때 캐싱 전략이 좋아보임
  - 서술형인 것을 고려 했을떄 다음과 같은 전략 
    - 키워드 기반 캐싱
    - 점수 범위 캐싱
    - 템플릿 기반 캐시
  - 도커 컨테이너로 저장 필요  
     - 캐시를 어떻게 추가할 지에 대해서는 고민 필요 
     - job queue를 별도로 이용해 비동기로 캐시에 데이터를 저장할 지..?
     - oci 무료 서버임을 감안할 필요 있음

2. 데이터 스키마 구조 최적화 및 변경
- 실제 질문과 유사하게 서술형 구조로 변경 필요 
- 이때 다음 문제를 적절하게 제시할 수 있도록 질문데이터 삽입 시 질문 키워드를 추출하여 유사도가 비슷한 다음질문을 제시 
- 즉 사용자가 1)서술형으로 정답을 제시할 수 있어야 하고 2)적절한 다음문제를 제시할 수 있어야 함
- migrate schema, gorm model, repository, api response  수정 필요 


3. ✅ 도메인 에러 구조 추가 및 에러 코드 응답 추가
- 현재 도메인 에러등 구조가 없다보니 에러발생시 500에러로 Raise
- 도메인 에러 중심 에러로 개편 및 에러 middleware를 추가하여 적절한 Status code로 Raise 필요


4. 질문 추가 배치 작업
- 상용 llm(gemmini api)를 이용해서 질문 데이터 추가
  - 이 때 미리 0~ 0.3 0.3~0.6 0.6~0.9 답변도 미리 만들어서 데이터를 저장하고 주기적으로 배치 작업을 통해 질문, 카테고리 추가 
  