version: "3.8"

services:
  oracle-db:
    image: container-registry.oracle.com/database/free:latest
    container_name: quiz-test-oracle-db-23ai
    environment:
      - TZ=Asia/Seoul
      - ORACLE_PWD=oracle # 강력한 비밀번호로 변경하세요!
      - DB_CHARACTERSET=AL32UTF8
      - DB_EDITION=FREE
      - DB_NAME=FREE # PDB (Pluggable Database) 이름 설정
    ports:
      - "1522:1521"
    # Oracle DB Healthcheck는 컨테이너 시작 시간이 매우 길어서
    # docker-compose up --wait 로 기다릴 때까지 시간이 오래 걸릴 수 있습니다.
    # 개발/테스트 환경에서는 주석 처리도 괜찮습니다.
    # 실제 프로덕션에서는 더 정교한 헬스체크가 필요할 수 있습니다.
    # healthcheck:
    #   test:
    #     [
    #       "CMD-SHELL",
    #       "/usr/bin/sqlplus -S sys/${ORACLE_PWD} as sysdba << EOF\nSELECT 1 FROM DUAL;\nEXIT;\nEOF || exit 1",
    #     ]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5
    #   start_period: 300s # Oracle DB는 시작 시간이 오래 걸리므로 충분히 길게 설정
    volumes:
      - oracle_data_23ai:/opt/oracle/oradata
    deploy:
      resources:
        limits:
          memory: 4G # Oracle DB는 메모리를 많이 사용합니다. 시스템 메모리에 따라 조정
          cpus: "2.0"
    restart: unless-stopped
    shm_size: "2gb"

  # llama-solver:
  #   # MacBook (Apple Silicon)에서 GPU(Metal)를 사용하려면 'platform: linux/amd64'를 제거해야 합니다.
  #   # llama.cpp 컨테이너 이미지가 arm64/v8을 지원해야 합니다.
  #   # 또는 로컬에서 Metal 지원 빌드된 llama.cpp 바이너리를 사용하여 이미지를 직접 만들어야 합니다.
  #   image:
  #     ghcr.io/ggerganov/llama.cpp:server # 이 이미지는 linux/amd64용일 수 있습니다.
  #     # Apple Silicon (arm64) 용으로 직접 빌드한 이미지를 사용하는 것이 최적입니다.
  #   # platform: linux/amd64 # <--- MacBook M1/M2/M3에서는 이 줄을 제거해야 합니다.
  #   container_name: quiz-test-llama-solver
  #   ports:
  #     - "8080:8080"
  #   volumes:
  #     - ./models:/models
  #     # MacBook Metal GPU 활용을 위한 중요한 변경!
  #     # n-gpu-layers를 0이 아닌 값 (예: 999)으로 설정해야 GPU를 사용합니다.
  #     # 이 값이 0이면 CPU만 사용합니다.
  #   command: --model /models/gemma-2-2b-it-Q5_K_M.gguf --host 0.0.0.0 --port 8080 --n-gpu-layers 999
  #   depends_on:
  #     oracle-db:
  #       condition: service_started
  #   deploy: # LLM 컨테이너에 리소스 제한 설정 (매우 중요)
  #     resources:
  #       limits:
  #         memory: 2.5G # Q5_K_M 모델 (1.92GB) 로드 및 추론에 필요한 메모리 고려
  #         cpus: "2.0" # LLM 추론에 사용될 CPU 코어 수
  #   restart: unless-stopped

#   llama-generator:
#     image: ghcr.io/ggerganov/llama.cpp:server # 위와 동일한 이유로 이미지 주의
#     # platform: linux/amd64 # <--- MacBook M1/M2/M3에서는 이 줄을 제거해야 합니다.
#     container_name: quiz-test-llama-generator
#     ports:
#       - "8081:8080" # 포트 충돌 방지를 위해 8081 사용
#     volumes:
#       - ./models:/models
#       # MacBook Metal GPU 활용을 위한 중요한 변경!
#       # n-gpu-layers를 0이 아닌 값 (예: 999)으로 설정해야 GPU를 사용합니다.
#     command: --model /models/gemma-2-2b-it-Q5_K_M.gguf --host 0.0.0.0 --port 8080 --n-gpu-layers 999
#     depends_on:
#       oracle-db:
#         condition: service_started
#     deploy: # LLM 컨테이너에 리소스 제한 설정 (매우 중요)
#       resources:
#         limits:
#           memory: 2.5G # Q5_K_M 모델 (1.92GB) 로드 및 추론에 필요한 메모리 고려
#           cpus: "2.0" # LLM 추론에 사용될 CPU 코어 수
#     restart: unless-stopped

  redis:
    image: "redis:alpine"
    container_name: quiz-test-redis
    ports:
      - "6380:6379" # Use a different host port for test Redis to avoid conflict if dev Redis is running
    volumes:
      - redis_data_test:/data

volumes:
  oracle_data_23ai:
    driver: local
  redis_data_test: # Define the redis_data_test volume
    driver: local
