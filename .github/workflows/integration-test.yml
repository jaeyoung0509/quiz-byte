name: Integration Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      oracle-db:
        image: gvenzl/oracle-xe:latest
        env:
          ORACLE_PASSWORD: oracle
          ORACLE_DATABASE: QUIZDB
        ports:
        - 1521:1521
        options: >-
          --health-cmd "sqlplus -L system/oracle@//localhost:1521/QUIZDB AS SYSDBA" --health-interval 10s --health-timeout 5s --health-retries 5

    steps:
    - uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.24'

    - name: Download LLM model
      run: |
        mkdir -p models
        if [ ! -f models/gemma-2b-it-q4_k_m.gguf ]; then
          curl -L https://huggingface.co/TheBloke/gemma-2b-it-GGUF/resolve/main/gemma-2b-it-q4_k_m.gguf -o models/gemma-2b-it-q4_k_m.gguf
        fi

    - name: Start LLM services
      run: |
        docker run -d --name llama-solver --platform linux/amd64 -p 8080:8080 -v $(pwd)/models:/models ghcr.io/ggerganov/llama.cpp:server --model /models/gemma-2b-it-q4_k_m.gguf --host 0.0.0.0 --port 8080
        docker run -d --name llama-generator --platform linux/amd64 -p 8081:8080 -v $(pwd)/models:/models ghcr.io/ggerganov/llama.cpp:server --model /models/gemma-2b-it-q4_k_m.gguf --host 0.0.0.0 --port 8080
        echo "Waiting for LLM services to start..."
        sleep 5

    - name: Run integration tests
      env:
        ENV: test
        DB_HOST: localhost
        DB_PORT: 1521
        DB_USER: system
        DB_PASSWORD: oracle
        DB_SERVICE: QUIZDB
        LLM_SOLVER_ENDPOINT: http://localhost:8080
        LLM_SOLVER_API_KEY: test_key
        LLM_GENERATOR_ENDPOINT: http://localhost:8081
        LLM_GENERATOR_API_KEY: test_key
      run: go test -v ./tests/integration/...

    - name: Cleanup
      if: always()
      run: |
        docker stop llama-solver llama-generator || true
        docker rm llama-solver llama-generator || true 
